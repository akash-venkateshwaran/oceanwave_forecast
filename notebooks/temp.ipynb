{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86ecc7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-21 03:40:33.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36moceanwave_forecast.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: D:\\CML\\Term 8\\ML projects\\forecasting_workspace\\oceanwave_forecast\u001b[0m\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (52650, 13)\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 52650 entries, 2024-01-01 00:00:00 to 2024-12-31 23:50:00\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   WDIR    52650 non-null  float64\n",
      " 1   WSPD    52650 non-null  float64\n",
      " 2   GST     52650 non-null  float64\n",
      " 3   WVHT    52650 non-null  float64\n",
      " 4   DPD     52650 non-null  float64\n",
      " 5   APD     52650 non-null  float64\n",
      " 6   MWD     52650 non-null  float64\n",
      " 7   PRES    52650 non-null  float64\n",
      " 8   ATMP    52650 non-null  float64\n",
      " 9   WTMP    52650 non-null  float64\n",
      " 10  DEWP    52650 non-null  float64\n",
      " 11  VIS     52650 non-null  float64\n",
      " 12  TIDE    52650 non-null  float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 5.6 MB\n",
      "\n",
      "Descriptive statistics:\n",
      "               WDIR          WSPD           GST          WVHT           DPD  \\\n",
      "count  52650.000000  52650.000000  52650.000000  52650.000000  52650.000000   \n",
      "mean     194.421026      4.962283      6.241216     66.211796     80.537227   \n",
      "std       96.600677      3.805890      4.484900     46.447783     37.382029   \n",
      "min        1.000000      0.000000      0.000000      0.030000      2.060000   \n",
      "25%      119.000000      2.300000      3.000000      0.550000     99.000000   \n",
      "50%      225.000000      4.300000      5.300000     99.000000     99.000000   \n",
      "75%      260.000000      6.900000      8.500000     99.000000     99.000000   \n",
      "max      999.000000     99.000000     99.000000     99.000000     99.000000   \n",
      "\n",
      "                APD           MWD          PRES          ATMP          WTMP  \\\n",
      "count  52650.000000  52650.000000  52650.000000  52650.000000  52650.000000   \n",
      "mean      67.337013    844.439943   1016.577221     10.072936     14.923626   \n",
      "std       44.857096    314.352896     78.656110     21.306571     71.185836   \n",
      "min        2.270000      0.000000    985.000000     -9.800000      8.000000   \n",
      "25%        4.230000    999.000000   1012.000000      8.100000      8.900000   \n",
      "50%       99.000000    999.000000   1016.600000      9.700000      9.600000   \n",
      "75%       99.000000    999.000000   1020.900000     11.500000     10.600000   \n",
      "max       99.000000    999.000000   9999.000000    999.000000    999.000000   \n",
      "\n",
      "               DEWP      VIS     TIDE  \n",
      "count  52650.000000  52650.0  52650.0  \n",
      "mean       7.827449     99.0     99.0  \n",
      "std       21.475054      0.0      0.0  \n",
      "min      -16.100000     99.0     99.0  \n",
      "25%        5.300000     99.0     99.0  \n",
      "50%        7.800000     99.0     99.0  \n",
      "75%       10.100000     99.0     99.0  \n",
      "max      999.000000     99.0     99.0  \n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # DeepAR for Ocean‑Wave Forecasting ‑ v2 (namedtuple + time_idx standardised)\n",
    "\n",
    "# %% 0️⃣ imports & seeds\n",
    "import warnings, numpy as np, pandas as pd, torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "import pytorch_forecasting as ptf\n",
    "from pytorch_forecasting import TimeSeriesDataSet, DeepAR\n",
    "from pytorch_forecasting.metrics import MAE\n",
    "from sktime.split import temporal_train_test_split\n",
    "\n",
    "from oceanwave_forecast import data_manager, data_pipeline, forecasting_utils, config, mlflow_utils, training\n",
    "import importlib\n",
    "importlib.reload(data_manager)\n",
    "importlib.reload(data_pipeline)\n",
    "importlib.reload(forecasting_utils)\n",
    "importlib.reload(config)\n",
    "importlib.reload(mlflow_utils)\n",
    "importlib.reload(training)\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "pl.seed_everything(42, workers=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# %% 1️⃣ feature configuration -------------------------------------------------\n",
    "FeatureConfig = namedtuple(\n",
    "    \"FeatureConfig\",\n",
    "    [\n",
    "        \"target\",\n",
    "        \"index_cols\",\n",
    "        \"static_categoricals\",\n",
    "        \"static_reals\",\n",
    "        \"time_varying_known_categoricals\",\n",
    "        \"time_varying_known_reals\",\n",
    "        \"time_varying_unknown_reals\",\n",
    "        \"group_ids\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "feat_cfg = FeatureConfig(\n",
    "    target              = \"Hs\",                              # <- main forecast target\n",
    "    index_cols          = [\"series\", \"timestamp\"],           # timestamp + series ID\n",
    "    static_categoricals = [\"series\"],                        # ocean buoy ID\n",
    "    static_reals        = [],\n",
    "    time_varying_known_categoricals = [],                    # e.g. holiday flags\n",
    "    time_varying_known_reals        = [\"time_idx\"],          # we always know time\n",
    "    time_varying_unknown_reals      = [],                    # filled later (lags & exog)\n",
    "    group_ids           = [\"series\"],\n",
    ")\n",
    "\n",
    "# %% 2️⃣ load & pre‑process raw data ------------------------------------------\n",
    "raw_path   = config.RAW_DATA_DIR / \"Standard meteorological data 2024\" / \"46088h2024.txt\"\n",
    "df_raw     = data_manager.extract_raw_data(raw_path)\n",
    "df_clean   = data_pipeline.preprocess_ocean_data(df_raw)\n",
    "df_clean   = df_clean.loc[config.START_DATE : config.END_DATE]\n",
    "\n",
    "# split target & features\n",
    "Y          = df_clean[config.TARGETS]\n",
    "X          = df_clean.drop(columns=config.TARGETS)\n",
    "\n",
    "# %% 3️⃣ initial train / test split (test = 3×horizon) -------------------------\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(\n",
    "    y=Y, X=X, test_size=config.HORIZON * 3\n",
    ")\n",
    "\n",
    "# %% 4️⃣ scaling pipelines (removes NaNs, redundant cols) ---------------------\n",
    "pipe_X, pipe_Y = data_pipeline.get_pipelines(list(X_train.columns))\n",
    "X_train_transformed  = pipe_X.fit_transform(X_train)\n",
    "X_test_transformed   = pipe_X.transform(X_test)\n",
    "y_train_transformed  = pipe_Y.fit_transform(y_train)\n",
    "y_test_transformed   = pipe_Y.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec6da2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1705a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf69e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that none of the dataframes X or y has timeindex cols. it is datatimeindexed but htere is not dedicated column for it.\n",
    "\n",
    "\n",
    "def tidy_long_df(X, y, buoy_id=\"buoy_46088\"):\n",
    "    \"\"\"\n",
    "    Merge features + targets and give PyTorch‑Forecasting its three required columns:\n",
    "      • series     – constant 'buoy_46088'\n",
    "      • time_idx   – 0…N counter per series (int64, contiguous)\n",
    "      • target     – numeric columns to predict\n",
    "    \"\"\"\n",
    "    # 1) concat horizontally, then pull the datetime index into a column\n",
    "    df = pd.concat([X, y], axis=1).reset_index()  \n",
    "    # 2) rename the datetime column\n",
    "    df.rename(columns={\"datetime\": \"timestamp\"}, inplace=True)\n",
    "    # 3) assign the single-series ID\n",
    "    df[\"series\"]   = buoy_id\n",
    "    # 4) zero‑based time index\n",
    "    df[\"time_idx\"] = np.arange(len(df), dtype=np.int64)\n",
    "    return df\n",
    "\n",
    "# build your full_df with vertical concat on X and y, then tidy:\n",
    "full_df = tidy_long_df(\n",
    "    pd.concat([X_train_transformed, X_test_transformed]),\n",
    "    pd.concat([y_train_transformed, y_test_transformed])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f45d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4080, 16) (72, 16) (216, 16)\n"
     ]
    }
   ],
   "source": [
    "max_pred_len   = config.HORIZON\n",
    "enc_len        = config.WINDOW\n",
    "n_test_steps   = max_pred_len * 3        # same logic you used\n",
    "\n",
    "cutoff         = full_df.time_idx.max() - n_test_steps\n",
    "train_cutoff   = cutoff - max_pred_len   # keep 1 horizon for validation\n",
    "\n",
    "train_df = full_df[full_df.time_idx <= train_cutoff]\n",
    "val_df   = full_df[(full_df.time_idx > train_cutoff) & (full_df.time_idx <= cutoff)]\n",
    "test_df  = full_df[full_df.time_idx >  cutoff]\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05c04653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               timestamp      WSPD       GST      PRES      ATMP      WTMP  \\\n",
      "4075 2024-06-18 19:00:00 -1.301136 -1.296310  0.440481  1.223932  2.686325   \n",
      "4076 2024-06-18 20:00:00 -1.385455 -1.393711  0.409650  1.389521  2.661535   \n",
      "4077 2024-06-18 21:00:00 -1.016558 -1.097275  0.368541  1.342210  2.364054   \n",
      "4078 2024-06-18 22:00:00 -0.821569 -0.923648  0.302767  1.300813  2.016993   \n",
      "4079 2024-06-18 23:00:00 -0.510641 -0.589099  0.247271  1.241674  3.008596   \n",
      "\n",
      "          DEWP  WDIR_sin  WDIR_cos   MWD_sin   MWD_cos      series      WVHT  \\\n",
      "4075  1.068871  0.826631 -1.428777 -0.693789 -0.624926  buoy_46088  0.059369   \n",
      "4076  1.082758  0.370505 -1.179541 -0.710523 -0.595855  buoy_46088 -0.421368   \n",
      "4077  1.179967 -1.034299 -0.436354 -0.706679 -0.595855  buoy_46088 -0.639885   \n",
      "4078  1.267918 -1.071429 -0.303864 -0.706724 -0.595855  buoy_46088 -0.712724   \n",
      "4079  1.323466 -1.047234 -0.426575 -0.706769 -0.595855  buoy_46088 -0.756427   \n",
      "\n",
      "           APD      series  time_idx  \n",
      "4075  0.979887  buoy_46088      4075  \n",
      "4076  0.094961  buoy_46088      4076  \n",
      "4077  0.006986  buoy_46088      4077  \n",
      "4078  0.436511  buoy_46088      4078  \n",
      "4079  0.798762  buoy_46088      4079  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b0bd5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label 'series' is not unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24864\\3111187802.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n",
      "\u001b[0;32m     23\u001b[0m     \u001b[0mtarget_normalizer\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mMultiNormalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalizers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     24\u001b[0m     \u001b[0mallow_missing_timesteps\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     25\u001b[0m )\n",
      "\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtrain_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeSeriesDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mTimeSeriesDataSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m     29\u001b[0m test_ds  = TimeSeriesDataSet.from_dataset(\n",
      "\u001b[0;32m     30\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\akashv22\\AppData\\Local\\anaconda3\\envs\\fc_env\\lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n",
      "\u001b[0;32m    487\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmin_prediction_idx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    488\u001b[0m             \u001b[1;31m# filtering for min_prediction_idx will be done on subsequence level ensuring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    489\u001b[0m             \u001b[1;31m# minimal decoder index is always >= min_prediction_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    490\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_prediction_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_encoder_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_lag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m--> 491\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_ids\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    493\u001b[0m         \u001b[1;31m# preprocess data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m    494\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\akashv22\\AppData\\Local\\anaconda3\\envs\\fc_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n",
      "\u001b[0;32m   7168\u001b[0m                 \u001b[1;34mf\"Length of ascending ({len(ascending)})\"\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   7169\u001b[0m                 \u001b[1;34mf\" != length of by ({len(by)})\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   7170\u001b[0m             )\n",
      "\u001b[0;32m   7171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 7172\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   7173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   7174\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   7175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;32mc:\\Users\\akashv22\\AppData\\Local\\anaconda3\\envs\\fc_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(.0)\u001b[0m\n",
      "\u001b[1;32m-> 7172\u001b[1;33m         \u001b[1;33m...\u001b[0m     \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_natsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akashv22\\AppData\\Local\\anaconda3\\envs\\fc_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n",
      "\u001b[0;32m   1921\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1922\u001b[0m                 \u001b[0mmulti_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1924\u001b[0m             \u001b[0mlabel_axis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"column\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m-> 1925\u001b[1;33m             raise ValueError(\n",
      "\u001b[0m\u001b[0;32m   1926\u001b[0m                 \u001b[1;34mf\"The {label_axis_name} label '{key}' is not unique.{multi_message}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m   1927\u001b[0m             )\n",
      "\u001b[0;32m   1928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: The column label 'series' is not unique."
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer, MultiNormalizer\n",
    "\n",
    "# build one GroupNormalizer *per* target\n",
    "normalizers = [\n",
    "    GroupNormalizer(\n",
    "        groups=[\"series\"],\n",
    "        transformation=\"softplus\"\n",
    "    )\n",
    "    for _ in config.TARGETS\n",
    "]\n",
    "\n",
    "common = dict(\n",
    "    time_idx                   = \"time_idx\",\n",
    "    target                     = config.TARGETS,\n",
    "    group_ids                  = [\"series\"],\n",
    "    time_varying_known_reals   = [\"time_idx\"],\n",
    "    time_varying_unknown_reals = [c for c in X_train_transformed.columns if c not in {\"series\"}],\n",
    "    static_categoricals        = [\"series\"],\n",
    "    max_encoder_length         = enc_len,\n",
    "    max_prediction_length      = max_pred_len,\n",
    "    # <-- use MultiNormalizer here:\n",
    "    target_normalizer          = MultiNormalizer(normalizers),\n",
    "    allow_missing_timesteps    = True,\n",
    ")\n",
    "\n",
    "train_ds = TimeSeriesDataSet(train_df, **common)\n",
    "val_ds   = TimeSeriesDataSet.from_dataset(train_ds, val_df)\n",
    "test_ds  = TimeSeriesDataSet.from_dataset(\n",
    "    train_ds, test_df,\n",
    "    predict=True, stop_randomization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c996ca63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label 'series' is not unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24864\\3111187802.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mtarget_normalizer\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mMultiNormalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalizers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mallow_missing_timesteps\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m )\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mtrain_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeSeriesDataSet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[0mval_ds\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mTimeSeriesDataSet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m test_ds  = TimeSeriesDataSet.from_dataset(\n\u001b[0;32m     30\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akashv22\\AppData\\Local\\anaconda3\\envs\\fc_env\\lib\\site-packages\\pytorch_forecasting\\data\\timeseries.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, data, time_idx, target, group_ids, weight, max_encoder_length, min_encoder_length, min_prediction_idx, min_prediction_length, max_prediction_length, static_categoricals, static_reals, time_varying_known_categoricals, time_varying_known_reals, time_varying_unknown_categoricals, time_varying_unknown_reals, variable_groups, constant_fill_strategy, allow_missing_timesteps, lags, add_relative_time_idx, add_target_scales, add_encoder_length, target_normalizer, categorical_encoders, scalers, randomize_length, predict_mode)\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmin_prediction_idx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;31m# filtering for min_prediction_idx will be done on subsequence level ensuring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[1;31m# minimal decoder index is always >= min_prediction_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_prediction_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_encoder_length\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_lag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_ids\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m         \u001b[1;31m# preprocess data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akashv22\\AppData\\Local\\anaconda3\\envs\\fc_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   7168\u001b[0m                 \u001b[1;34mf\"Length of ascending ({len(ascending)})\"\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7169\u001b[0m                 \u001b[1;34mf\" != length of by ({len(by)})\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7170\u001b[0m             )\n\u001b[0;32m   7171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7172\u001b[1;33m             \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7174\u001b[0m             \u001b[1;31m# need to rewrap columns in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\akashv22\\AppData\\Local\\anaconda3\\envs\\fc_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m-> 7172\u001b[1;33m         \u001b[1;33m...\u001b[0m     \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_natsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\akashv22\\AppData\\Local\\anaconda3\\envs\\fc_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1921\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1922\u001b[0m                 \u001b[0mmulti_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m             \u001b[0mlabel_axis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"column\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1925\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1926\u001b[0m                 \u001b[1;34mf\"The {label_axis_name} label '{key}' is not unique.{multi_message}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1927\u001b[0m             )\n\u001b[0;32m   1928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The column label 'series' is not unique."
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data.encoders import GroupNormalizer, MultiNormalizer\n",
    "\n",
    "# build one GroupNormalizer *per* target\n",
    "normalizers = [\n",
    "    GroupNormalizer(\n",
    "        groups=[\"series\"],\n",
    "        transformation=\"softplus\"\n",
    "    )\n",
    "    for _ in config.TARGETS\n",
    "]\n",
    "\n",
    "common = dict(\n",
    "    time_idx                   = \"time_idx\",\n",
    "    target                     = config.TARGETS,\n",
    "    group_ids                  = [\"series\"],\n",
    "    time_varying_known_reals   = [\"time_idx\"],\n",
    "    time_varying_unknown_reals = [c for c in X_train_transformed.columns if c not in {\"series\"}],\n",
    "    static_categoricals        = [\"series\"],\n",
    "    max_encoder_length         = enc_len,\n",
    "    max_prediction_length      = max_pred_len,\n",
    "    # <-- use MultiNormalizer here:\n",
    "    target_normalizer          = MultiNormalizer(normalizers),\n",
    "    allow_missing_timesteps    = True,\n",
    ")\n",
    "\n",
    "train_ds = TimeSeriesDataSet(train_df, **common)\n",
    "val_ds   = TimeSeriesDataSet.from_dataset(train_ds, val_df)\n",
    "test_ds  = TimeSeriesDataSet.from_dataset(\n",
    "    train_ds, test_df,\n",
    "    predict=True, stop_randomization=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c0558c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch   = 64\n",
    "\n",
    "train_loader = train_ds.to_dataloader(train=True,  batch_size=batch, num_workers=4)\n",
    "val_loader   = val_ds  .to_dataloader(train=False, batch_size=batch)\n",
    "test_loader  = test_ds .to_dataloader(train=False, batch_size=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd94d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DeepAR.from_dataset(train_ds, hidden_size=64, rnn_layers=2)\n",
    "trainer.fit(net, train_loader, val_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
